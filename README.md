.# Kaggle Competition Entry - TalkingData Fraud Detection

Author: Gaurab Bose

I have used Gradient Boosting (XGBoost) to predict the probabilities of a fraudulent click, that will be assessed by it's AUC score.

The script includes data importing, preprocessing, model training, cross validation and test prediction. The entire training file was too large to upload but the script will work on the uploaded 'sample training data' which is a small subset of the original.

The orignial Kaggle challenge for which this script was written, can be found [here](https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection).
